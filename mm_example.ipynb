{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tduckenfield/wisa_motionmag_tutorial/blob/main/mm_example.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src=\"https://github.com/Tduckenfield/wisa_motionmag_tutorial/blob/main/figs/Anfinogentov_mm_example.jpg?raw=true\">"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"prlJF-xB5S8C"},"source":["# Motion magnification\n","Motion magnification is a processing technique which amplifies small transverse quasi-periodic motions of contrasted features in image sequences: it acts as a **microscope for videos**.\n","\n","Consider the humble microscope: through amplifying the image of small objects, microscopes have allowed us to view the world of tiny things the human eye cannot see. They led to some of the greatest scientific breakthroughs in history - for example cellular biology, forensic science, the existence of bacteria + viruses etc. Can we do the same thing but to small spatial scales changing over time in a video?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"executionInfo":{"elapsed":4055,"status":"ok","timestamp":1687384448415,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"JEL5m-Ro5Esz","outputId":"99aae59c-5f42-46e8-e8d2-af9b66d4bbc8"},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from matplotlib import animation\n","from IPython.display import HTML # To display video\n","from base64 import b64encode\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Show video\n","mp4 = open('/content/gdrive/MyDrive/sergey.mp4','rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=800 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ahlGX66Q86Kp"},"source":["This is [Dr Sergey Anfinogentov](https://orcid.org/0000-0002-1107-7420). He has provided everyone with a [code on Github](https://github.com/Sergey-Anfinogentov/motion_magnification) which can motion magnify any video. I aim to help you run motion magnification, and explain how it works!\n","\n","You can see in the video above, that whilst the video on the left looks quite static, there are a whole range of motions which are much more obvious on the right. **These motions were always there**.\n","\n","This processing tool has been used by me and others for use in solar physics, notably Sihui Zhong, Sudip Mandal, Yuhang Gao & Valery Nakariakov, all of whom are  here today! Hi! By magnifying the transverse motions of coronal structures seen in EUV, we have been able to study in great detail the regime of *decayless kink oscillations*.\n","\n","These MHD waves are everywhere in the corona, so it is highly likely you could motion magnify any image sequence of the Sun where coronal structures are resolved (e.g. SDO/AIA 17.1 nm) and find some of these transverse waves. To prove me right/wrong, try going through the [mm_solardata]() notebook and give it a go!   "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IN4xjXLnAo77"},"source":["# Working example\n","Let us do some motion magnification as a \"black box\" process. Feel free to use any video! Here I have picked one of my *gorgeous* dog Daphne, which you can access from my shared Google Drive and is also in this github repository."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":247,"output_embedded_package_id":"1K_Fs1AbBdIK_AuUDnZ6dTzrKgIjIerNw"},"executionInfo":{"elapsed":19399,"status":"ok","timestamp":1687385765498,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"vEEaGtK6BLn2","outputId":"4ebb17ee-8e0d-48fe-bdc5-b14ea25fd771"},"outputs":[],"source":["# Input video path\n","daphne_path = \"/content/gdrive/MyDrive/daphne_garden.MOV\"\n","#\"/content/gdrive/MyDrive/daphne_sleeping_compressed.mp4\"\n","\n","# Show video\n","mp4 = open(daphne_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6PeNEGyBeOd"},"outputs":[],"source":["import cv2\n","\n","input_video_filename = compressed_path\n","\n","videoReader = cv2.VideoCapture(input_video_filename)  # create video object\n","nFrames = int(videoReader.get(cv2.CAP_PROP_FRAME_COUNT))\n","frameWidth = int(videoReader.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frameHeight = int(videoReader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","print(\"Total Number of Frames = \", nFrames)\n","print(\"Each frame has dimensions = \",frameHeight,\"x\", frameWidth) # Which way around?\n","\n","# Note we specify float32 since necessary for cv2.color_bgr2gray\n","img_array_rgb = np.zeros((nFrames, frameHeight,frameWidth, 3), np.dtype(\"float32\"))\n","img_array = np.zeros((nFrames, frameHeight,frameWidth), np.dtype(\"float32\"))\n","\n","nf = 0\n","ret = True\n","\n","while (nf < nFrames  and ret):  # Could do for loop as well\n","#\t\tprint(\"frame: \" + str(nf))\n","    ret, img_array_rgb[nf] = videoReader.read()\n","    img_array[nf] = cv2.cvtColor(img_array_rgb[nf], cv2.COLOR_RGB2GRAY)\n","    nf += 1\n","#\t\tif ret == False or img is None:\n","#\t\t\t\tprint(\"done\")\n","#\t\t\t\tbreak\n","\n","#videoWriter = make_video_writer(videoReader, output_video_filename)\n","\n","videoReader.release()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip --quiet install dtcwt\n","!git clone https://github.com/Sergey-Anfinogentov/motion_magnification.git\n","%cd /content/motion_magnification\n","from magnify import *"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RpXm49s370Xv"},"source":["# History\n","There have been multiple routines developed for motion magnification since around 2005. The early attempts focussed on directly estimating the velocity field between frames, in the so-called *Lagrangian* approach.  "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPE8ZpP+bamGFNshKuytpB7","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

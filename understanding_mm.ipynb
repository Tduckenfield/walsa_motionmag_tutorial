{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Tduckenfield/wisa_motionmag_tutorial/blob/main/understanding_mm.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"13Lu-pORDBpY"},"source":["# Motion magnification: under the hood\n","This notebook explains the inner workings motion magnification code, and demonstrates the effect of parameters `k` and `width`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4teR6ZGpjYO"},"outputs":[],"source":["%matplotlib inline\n","import numpy as np\n","from matplotlib import pyplot as plt\n","from matplotlib import animation"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"hCUjZdjfC0J_"},"source":["First, let us create a numpy datacube containing a ring which oscillates from side to side. This will serve as a good test to show clearly what the MM is doing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9rTHb4OozNKu"},"outputs":[],"source":["# Define the dimensions of the array. Small to make MM quick!\n","width, height = 100, 100\n","nframes = 200\n","\n","# Create an empty array with the specified dimensions\n","frames = np.zeros((nframes, width, height))\n","\n","# Oscillation parameters\n","radius = 10   # inner radius of ring in pixels. Ring will have width of 1 pixel.\n","period = 50   # period in frames\n","amplitude = 0.5 # oscillation amplitude in pixels\n","thick = 2    # thickness of ring in pixels\n","\n","# Generate the frames\n","for frame in range(nframes):\n","    # Calculate the center position of the circle based on the frame index\n","    # The circle oscillates horizontally with a period of 10 frames\n","    center_x = float(width / 2 + amplitude * np.sin(2 * np.pi * frame / period))\n","    center_y = float(height / 2)\n","\n","    # Create a meshgrid of coordinates\n","    x, y = np.meshgrid(np.arange(width), np.arange(height))\n","\n","    # Calculate the distance from each point to the center of the circle\n","    distance = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n","\n","    # Assign a value of 1 to points inside the circle\n","    frames[frame][(distance >= radius) & (distance <= radius + thick)] = 1\n","\n","## Plot all the frames\n","#plt.figure(figsize=(8, 8))\n","#for frame in range(200):\n","#    plt.subplot(10, 20, frame + 1)\n","#    plt.imshow(frames[frame], cmap='gray', vmin=0, vmax=0.1) # make easier to see\n","#    plt.axis('off')\n","#\n","#plt.tight_layout()\n","#plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TUHSs1yJDXK-"},"source":["If you like, we can plot a subsection of frames to see the oscillation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"elapsed":1365,"status":"ok","timestamp":1687277545698,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"YF-rIGEN3UKx","outputId":"567c5d00-7caf-4b80-c1d1-6014fbc8c899"},"outputs":[],"source":["# Determine the number of rows and columns in the grid\n","num_rows = 5\n","num_cols = 4\n","\n","# Calculate the number of frames to plot\n","num_frames = float(num_rows * num_cols)\n","ntp = np.floor(200 / num_frames)\n","\n","for i, frame in enumerate(range(0, 200, int(ntp))):\n","    plt.subplot(num_rows, num_cols, i + 1)\n","    plt.imshow(frames[frame], cmap='gray')\n","    plt.title('Frame {}'.format(frame))\n","    plt.axis('off')\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C5DFG93mEhxL"},"source":["Now we make a function to do a quick animation of the datacube.\n","This assumes time is the first dimension, i.e. nframes = cube_array.shape[0]. \\\\\n","Please forgive my poor Python skills!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfRaZ8Vjjs9n"},"outputs":[],"source":["from matplotlib.animation import FuncAnimation\n","from IPython.display import HTML\n","\n","def animate_cube(cube_array, cut=True, mn=0, sd=0, interval=75, cmap='gray', plot_cbar=True):\n","    '''\n","    animate a python datacube for quick visualisation. Colourbar range of 6 standard deviations around mean unless specified.\n","\n","    INPUT:\n","        cube_array  : name of 3D numpy array that needs to be animated, with nframes being 1st dimension.\n","        cut         : trim #pixels off of the image's edge to remove edge detector effects.\n","                      Note default = True since 0 returns empty array(?!).\n","        mn          : mean of the cube | Used for contrast\n","        sd          : std of the cube  | Used for contrast\n","        interval    : #of ms between each frame.\n","        cmap        : colormap. Default='gray', consider 'hot'\n","        plot_cbar   : set to False to not show colourbar.\n","\n","    OUTPUT:\n","        animated window going through the cube.\n","\n","    '''\n","\n","    fig = plt.figure()\n","    std = np.std(cube_array[0])\n","    mean = np.mean(cube_array[0])\n","    if mn==sd and mn==0:\n","        img = plt.imshow(cube_array[0][cut:-cut, cut:-cut], animated=True, vmax=mean+3*std, vmin=mean-3*std, cmap=cmap)\n","    else:\n","        img = plt.imshow(cube_array[0][cut:-cut, cut:-cut], animated=True, vmax=mn+3*sd, vmin=mn-3*sd, cmap=cmap)\n","\n","    def updatefig(i):\n","        img.set_array(cube_array[i][cut:-cut, cut:-cut])\n","        return img,\n","\n","    ani = FuncAnimation(fig, updatefig, frames=cube_array.shape[0],                                  interval=interval, blit=True)\n","    if plot_cbar==True:\n","        plt.colorbar()\n","\n","    # Set up the HTML video player\n","    video = HTML(ani.to_jshtml())\n","\n","    # Display the video player\n","    display(video)\n","    plt.show()\n","    # ani.save('cube_movie.avi', writer=\"ffmpeg\", fps=15)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":995,"output_embedded_package_id":"1l6dybJ6m6IktvaP_XIgr1K2enQncP_sk"},"executionInfo":{"elapsed":16999,"status":"ok","timestamp":1687277107161,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"4T7rxpWloPXL","outputId":"016ecd5b-7061-416e-801e-9cb69c43cb3c"},"outputs":[],"source":["animate_cube(frames, plot_cbar=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yPiZo4ZzGaJP"},"source":["Now we get to the good bit: **motion magnification**! We need the Dual Tree Complex Wavelet Transform library, and the MM algorithm we will use based on it, from our colleague [Sergey Anfinogentov's github](https://github.com/Sergey-Anfinogentov/motion_magnification.git)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12895,"status":"ok","timestamp":1687276100467,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"azxwwgYB6zC_","outputId":"ccefaeb9-bb39-48bc-b511-c89b6aa96bb6"},"outputs":[],"source":["%pip --quiet install dtcwt\n","!git clone https://github.com/Sergey-Anfinogentov/motion_magnification.git\n","%cd /content/motion_magnification\n","from magnify import *"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cqtHTmGge5Fz"},"source":["Let us motion magnify this data. Very simply..."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10451,"status":"ok","timestamp":1687277126494,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"K-AKQFdofA5r","outputId":"9c120972-badb-4b30-8334-857d758f9500"},"outputs":[],"source":["k = 5      # Pick a magnification factor\n","width= 120 # width\n","frames_k5w120 = magnify_motions_2d(frames, k, width)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":995,"output_embedded_package_id":"1TiRCSN2A5O2GtcDSUkrLG7o7dzME2xh9"},"executionInfo":{"elapsed":17999,"status":"ok","timestamp":1687277145297,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"6gIJj1wAfkpj","outputId":"651e1904-483c-49a5-e8b9-633f2d03ec75"},"outputs":[],"source":["animate_cube(frames_k5w120, plot_cbar=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JUCnoNtFjGwu"},"source":["Clearly we have magnified the oscillation! We can take a quick look at a \"time distance plot\" - just a cut of pixels through the centre."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":1039,"status":"ok","timestamp":1687277156322,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"z0CSetsVg1is","outputId":"80a2ab57-d9b2-4036-fa99-42639b8e5fc9"},"outputs":[],"source":["frames_k5w120.shape\n","td_orig = np.transpose(frames[:,50,:])\n","td_k5w120 = np.transpose(frames_k5w120[:,50,:])\n","\n","f, axarr = plt.subplots(2, sharex=True)\n","axarr[0].imshow(td_orig, vmin=-1., vmax=1.)\n","axarr[0].set_title('No magnification')\n","axarr[0].axis(\"tight\")\n","axarr[0].set_ylabel(\"Pixel\")\n","axarr[0].axis(\"image\")\n","axarr[1].imshow(td_k5w120, vmin=-1., vmax=1.)\n","axarr[1].set_title('After motion magnification x5')\n","axarr[1].axis(\"tight\")\n","axarr[1].set_ylabel(\"Pixel\")\n","axarr[1].set_xlabel(\"Time\")\n","axarr[1].axis(\"image\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9QK1_Hlr14PG"},"source":["It is clear to see that the oscillation is more visible after motion magnification, whilst the period remains the same."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oCgrbxQ-jLRN"},"source":["Now that we have seen how the MM is implemented, let us dig into the detail. You can see that there are only 2 parameters we need for this function.\n","\n","# Magnification factor `k`\n","This is simply the factor by which we will scale the phases in our specified period band, which will amplify any coherent displacements with periods lying within this band.\n","\n","\\\\\n","Thinking about what the magnification is doing \"under the hood\", every wavelet component (in the 6 directions and for each scale) only `feels' the intensity distribution near its own position, within the size of the envelope of the mother wavelet. When we change the phases, we modify the reconstructed image but *only* in the local spatial neighbourhood of that component. We can not 'move' this component beyond the envelope of the mother wavelet (remember we leave the component's absolute value alone). Thus there is an upper limit on how much we can amplify motions. Trying to move beyond this limit will try to translate signal beyond where the absolute value is constant, losing the linear scaling property whilst also leading to distortion.\n","\n","\\\\\n","In the solar case, when using a wide period band + short filter banks whilst searching for oscillation amplitudes $\\lt$ 5 pixels, we can not push the amplification too far (see below for [Fig. 3a Anfinogentov & Nakariakov 2016](http://link.springer.com/10.1007/s11207-016-1013-z)). Further analysis of the signal will benefit from less distortion of features, so I recommend keeping `k` as small as possible while still highlighting previously hidden features.\n","In my experience, `k=5` is a good starting point when initially searching for decayless oscillations in solar data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":1912,"status":"ok","timestamp":1687242884932,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"L3j60HvHfzjS","outputId":"3121b36f-a6c9-4514-e581-efec9f3657ae"},"outputs":[],"source":["<img src=\"https://github.com/Tduckenfield/wisa_motionmag_tutorial/blob/main/figs/Anfinogentov2016_scaling.PNG?raw=true\">"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_DULI-90muqc"},"source":["# Smoothing window width `w`\n","This is a period (in frames) which determines the length of the filter applied to the phases which are amplified during MM. Any oscillations with periodicity less than `w` should be linearly amplified by the motion magnification.\n","This parameter **must** be greater than the periodicity of the signal of interest.\n","\n","Since we do not know exactly what oscillation period we are looking for, we must ensure we stay in the regime where the period scaling is the same for all periods. As you can see from the (figure below [Fig. 3b Anfinogentov & Nakariakov 2016](http://link.springer.com/10.1007/s11207-016-1013-z)), the scaling is not perfectly linear for very short oscillations. Further, recall the MM has a 2-frame smoother on the amplified phases. Thus one must be careful when oscillations appear at very short periods ($\\lt$10 frames) and check they are not artefacts... thank goodness for the time resolution of SoLO/HRI!\n","\n","Nonetheless it is worth stressing, it is **remarkable** how we can enhance *all* periodic signals less than the smoothing width linearly using the MM algorithm.\n","\n","In my experience, using a smoothing width greater than or equal to 120 frames for 12 second cadence SDO/AIA data works well."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1687245575862,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"XpSeSu7MqznP","outputId":"cd85f684-e55d-4077-d146-7ff7d32ab7e4"},"outputs":[],"source":["<img src=\"https://github.com/Tduckenfield/wisa_motionmag_tutorial/blob/main/figs/Anfinogentov2016_MM_fig3_width.PNG?raw=true\">"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NbIEPeNilJv5"},"source":["# Potency of MM in sub-pixel regime\n","\n","Another remarkable property of the MM algorithm here is the robustness of the amplification:\n","\n","1.  When multiple structures are oscillating close to each other (see [Fig 5 Anfinogentov & Nakariakov 2016](http://link.springer.com/10.1007/s11207-016-1013-z))\n","2.  The scaling of the magnified amplitude to input  amplitude, which remains linear even for initial amplitudes of 0.01 pixel!\n","3.  The  transverse intensity profile is found to keep its steepness + shape well after magnification. This is important when considering the study of coronal loops, since transverse density structuring (and possible development of turbulence etc) are important physical effects.\n","\n","For more information, the reader is recommended to see [Zhong+ 2021](http://dx.doi.org/10.1007/s11207-021-01870-w) or ask Sihui at the dinner!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18366,"status":"ok","timestamp":1687169075207,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"SHNjGWUXG3gl","outputId":"744b96d6-2463-416d-a184-274283526460"},"outputs":[],"source":["k = 2 #Magnification\n","width= 120 # width\n","frames_k2w120 = magnify_motions_2d(frames, k, width)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":995,"output_embedded_package_id":"1EQkAAdVbGknt58tt7cjkW0WWVksxjJrm"},"executionInfo":{"elapsed":31575,"status":"ok","timestamp":1687169113262,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"6EgBs8N1HLrm","outputId":"aff21fa2-0d10-4421-e399-a185dece7e02"},"outputs":[],"source":["animate_cube(frames_k2w120, plot_cbar=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"elapsed":1629,"status":"ok","timestamp":1687169186128,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"zB-K3rOMHR4u","outputId":"97c58b98-c75a-4b38-d13a-8b87ff1d6aed"},"outputs":[],"source":["for i, frame in enumerate(range(0, 200, int(ntp))):\n","    plt.subplot(num_rows, num_cols, i + 1)\n","    plt.imshow(frames_k5w80[frame], cmap='gray')\n","    plt.title('Frame {}'.format(frame))\n","    plt.axis('off')\n","\n","# Adjust the spacing between subplots\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10557,"status":"ok","timestamp":1687168950008,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"L9QktkRuGcP-","outputId":"089f18b4-a8be-43a2-dc0b-8e74d2934be5"},"outputs":[],"source":["k= 5 #Magnification\n","width= 80 # width\n","frames_k5w80 = magnify_motions_2d(frames, k, width)\n","animate_cube(frames_k5w80, plot_cbar=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TdUEJQGFSArJ"},"source":["# Pseudo code\n","Let us consider what is happening in the motion magnification.\n","The pseudo code for the algorithm goes something like this:\n","\n","1. Load in image sequence, ensuring first frame is data[0,:,:]\n","2. Transform each frame of our video into the DT$\\mathbb{C}$WT space. Each image $I^t$ is decomposed into a low pass image $L^t$ and a number of high pass images $H^t_s$ for different spatial scales $s$\n","> Recall that for each scale/level, the image was decomposed with (2) wavelet(s) in 6 directions to form *complex* coefficients.\n","We collect all these coefficients into the `pyramid` which has as many elements as there are frames.\n","3. For each level, calculate the phases from our pyramid of $H^t_s$.\n","> We actually get the array of *cumulative* angle against time for that scale, which avoids phase discontinuities as 0 $â†’2\\pi$. The formula is $\\Phi^t_s(x,y) = \\sum_{\\tau = 0}^t \\phi\\left(H^{\\tau+1}_s(x,y) / H^{\\tau}_s(x,y \\right)$.\n","4. Calculate a phase trend $\\overline{\\Phi}^t_s$, which is $\\Phi^t_s$ smoothed through convolution with a filter of length `w`. This trend will be maintained through the MM, since we need \"good\" phase information to reconstruct the intensity image.\n","> The filter used is a flattop filter, not Gaussian or boxcar. The flattop filter is carefully designed to take the most accurate measurement of *signal amplitude* in frequency space (minimal power in scallops, as flat as possible).\n","5. Now we multiply the high frequency variations of the phase, which is simply the phases minus trend $\\Phi^t_s - \\overline{\\Phi}^t_s$, by the magnification factor ```k```.\n","> In total we get $\\begin{equation} (\\Phi_\\text{out})^t_s = \\overline{\\Phi}^t_s + k\\left({\\Phi}^t_s - \\overline{\\Phi}^t_s\\right) \\end{equation}$, so all motions with timescales $\\lt$ `w` are amplified.\n","6. It is important to note **we also smooth the array of phases output $(\\Phi_\\text{out})^t_s$ by a filter of width 2**. This was found to greatly improve the result of MM on solar data, since high-frequency noise in the phase will also be amplified in the previous step.\n","> **Of crucial importance:** the oscillation of interest must have a periodicity greater than this smoothing window, else false oscillations may appear. \\\\\n","> You can see the effect this phase smoothing alone has by setting your width equal to the length of the data and no magnification, `k=1`, `w=nframes`.)\n","7. We construct the output high pass images by recombining the (original) absolute values with the new phases, $(H_\\text{out})^t_s = |H^t_s| \\exp i (\\Phi_\\text{out})^t_s $.\n","8. Finally we transform back to get our motion magnified images, combining the modified high pass complex components $H_\\text{out}^t$ for all scales $s$ with the low pass image $L^t$.\n","\n","Note: SA's function ``` phase(pyramids...) ``` will return all numbers with modulus 1 where 0 -> 1. This is to be used for extracting the angles from. Note we do not look at the angles as they evolve over a pyramid level, since this would be moving spatially across one frame. We care about phase changes *temporally* so we must make an array of phases for each scale.\n","\n","Note 2: now it should be more clear why the magnification of the annulus appears to have an aura-like artefact. The annulus has a steep + poorly resolved jump across the boundary and so is prone to ringing.\n","I think of it like this: the wave troughs in the low pass image (remember we sacrifice spatial resolution for spectral when using a wavelet) are not sufficiently `filled in' by the high pass components, since we have modified the phases in MM. Had we left the high pass components unchanged, the reconstruction would be perfect despite the low pass appearing ringy.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iluMK4N8ixVL"},"source":["# Effect of the two frame smoother\n","The following plot shows the smoother (flattop filter of width 2) used inside the motion magnification routine. This filter is convolved with the array of (cumulative) phases post-magnification, before being transformed back into an image sequence. Note that this mildly denoises the image, since a small incoherent change in the intensity will be spread across the phases at many scales."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1687179366465,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"LiPOe6gfMYAL","outputId":"c78566c3-4d30-4ab2-ce30-0bc6b5479112"},"outputs":[],"source":["from scipy import signal\n","fig, ax = plt.subplots()\n","window_size =  round(2/0.2327)\n","window = signal.flattop(window_size)\n","window = window/np.sum(window)    # Normalise\n","ax.plot(window)\n","ax.set_ylabel('Normalised filter amplitude')\n","ax.set_title('Two-frame (phase) smoother used within MM')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fa8_RdAI1HZd"},"source":["Here we isolate the effect of the 2 frame smoother only."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1LoNl9qvwBFFo14Jh2yi_p7dG6o26HHbV"},"executionInfo":{"elapsed":63823,"status":"ok","timestamp":1687186077055,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"drroOHYNpHfi","outputId":"31ff115f-1079-40b8-8b2f-9aebb754d057"},"outputs":[],"source":["k= 1 # No magnification\n","width = nframes # Set the phase `trend' to be the whole duration. May be some apodisation.\n","frames_onlysmooth = magnify_motions_2d(frames, k, width)\n","animate_cube(frames_onlysmooth)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xUc99wh_vaji"},"source":["To finish, let us return to my *gorgeous* dog again! We can motion magnify any video, so why not this video of her sleeping which I took last night. Not creepy at all... \\\\\n","First let us animate the original video."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":5115,"status":"ok","timestamp":1687280545115,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"CmhpgJltvaWJ","outputId":"88345ec5-ad85-474d-b6e5-19e00e697d1a"},"outputs":[],"source":["from IPython.display import HTML\n","from base64 import b64encode\n","import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Input video path\n","save_path = \"/content/gdrive/MyDrive/daphne_sleeping.mov\"\n","\n","# Compressed video path. Works with mp4, mov etc. Compress since colab sometimes fails if too big.\n","compressed_path = \"/content/gdrive/MyDrive/daphne_sleeping_compressed.mp4\"\n","\n","# Use ffmpeg to convert video\n","os.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n","\n","# Show video\n","mp4 = open(compressed_path,'rb').read()\n","data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","HTML(\"\"\"\n","<video width=400 controls>\n","      <source src=\"%s\" type=\"video/mp4\">\n","</video>\n","\"\"\" % data_url)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MmLMYhlQwuOR"},"source":["You can see large intensity variations from the light of the TV. Now let us read in the mp4 as a numpy array."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":887,"status":"ok","timestamp":1687280845951,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"Tw8zZqtCwG7y","outputId":"f977590b-e64e-4fe3-a424-49110b9d5027"},"outputs":[],"source":["import cv2\n","\n","input_video_filename = compressed_path\n","\n","videoReader = cv2.VideoCapture(input_video_filename)  # create video object\n","nFrames = int(videoReader.get(cv2.CAP_PROP_FRAME_COUNT))\n","frameWidth = int(videoReader.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frameHeight = int(videoReader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","print(\"Total Number of Frames = \", nFrames)\n","print(\"Each frame has dimensions = \",frameHeight,\"x\", frameWidth) # Which way around?\n","\n","# Note we specify float32 since necessary for cv2.color_bgr2gray\n","img_array_rgb = np.zeros((nFrames, frameHeight,frameWidth, 3), np.dtype(\"float32\"))\n","img_array = np.zeros((nFrames, frameHeight,frameWidth), np.dtype(\"float32\"))\n","\n","nf = 0\n","ret = True\n","\n","while (nf < nFrames  and ret):  # Could do for loop as well\n","#\t\tprint(\"frame: \" + str(nf))\n","    ret, img_array_rgb[nf] = videoReader.read()\n","    img_array[nf] = cv2.cvtColor(img_array_rgb[nf], cv2.COLOR_RGB2GRAY)\n","    nf += 1\n","#\t\tif ret == False or img is None:\n","#\t\t\t\tprint(\"done\")\n","#\t\t\t\tbreak\n","\n","#videoWriter = make_video_writer(videoReader, output_video_filename)\n","\n","videoReader.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":997,"output_embedded_package_id":"1vc-Y3GUCllDZL4_EZuxpfEuixnWHHPaT"},"executionInfo":{"elapsed":34065,"status":"ok","timestamp":1687280974676,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"nhuL5LAoxFtA","outputId":"962a5918-7138-423c-d721-d7be3c84dd99"},"outputs":[],"source":["animate_cube(img_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48598,"status":"ok","timestamp":1687281091585,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"_bo6y9fExwEw","outputId":"8e5687fc-e535-49c2-fe11-fc0b156c9f39"},"outputs":[],"source":["daphne_mag = magnify_motions_2d(img_array, 5, 80)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":997,"output_embedded_package_id":"1lw6HFclQTL39IqvO8D6j0l06Ld6wvhPj"},"executionInfo":{"elapsed":39584,"status":"ok","timestamp":1687281133180,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"RY42iogwyYUZ","outputId":"c23f85ff-9790-416d-cc88-12796cbec889"},"outputs":[],"source":["animate_cube(daphne_mag)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"executionInfo":{"elapsed":1481,"status":"ok","timestamp":1687282117869,"user":{"displayName":"Tim Duckenfield","userId":"13806276132819639191"},"user_tz":-60},"id":"4mQTIITbykrH","outputId":"c8dd5e48-1486-41b5-aae5-7d75243bdce9"},"outputs":[],"source":["td_daphne_orig = np.transpose(img_array[:,250:300,400]) # 250:300,400 ~ top of chest. Non-sinusoidal!\n","td_daphne_mag = np.transpose(daphne_mag[:,250:300,400]) # 200:250,250 ~ through nose. Remarkably still!\n","\n","plt.figure()\n","plt.imshow(daphne_mag[0,200:350,350:450], cmap='gray') # [0,200:300,225:275] shows her nose\n","\n","f, axarr = plt.subplots(2, sharex=True)\n","axarr[0].imshow(td_daphne_orig, cmap='gray')\n","axarr[0].set_title('No magnification')\n","axarr[0].axis(\"tight\")\n","axarr[0].axis(\"image\")\n","axarr[1].imshow(td_daphne_mag, cmap='gray')\n","axarr[1].set_title('After motion magnification x5')\n","axarr[1].axis(\"tight\")\n","axarr[1].axis(\"image\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MgeN9OAc0elf"},"source":["You can see her breathing is quite non-sinusoidal! Yet her nose is amazingly still."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOQqVNATv/k/eoRMLP5JR10","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
